<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>dash-webapp-template.seqapp.bioinfo.pipeline API documentation</title>
<meta name="description" content="seqapp Core Bioinformatics Pipeline …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dash-webapp-template.seqapp.bioinfo.pipeline</code></h1>
</header>
<section id="section-intro">
<p>seqapp Core Bioinformatics Pipeline</p>
<h2 id="overview">Overview</h2>
<p>Contains the main seqapp functionality relies on for processing
(i.e., via a 'run' of the 'pipeline') user-uploaded inputt and returning
transformed results.
These returned results data are displayed reactive-
ly via the UI and made available for direct file downloads via custom HTML-
transforming functions triggered by user callbacks and thus located in the
callbacks.py module.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python3.7
&#34;&#34;&#34;seqapp Core Bioinformatics Pipeline

Overview
--------
Contains the main seqapp functionality relies on for processing
(i.e., via a &#39;run&#39; of the &#39;pipeline&#39;) user-uploaded inputt and returning 
transformed results.  These returned results data are displayed reactive-
ly via the UI and made available for direct file downloads via custom HTML-
transforming functions triggered by user callbacks and thus located in the
callbacks.py module.
&#34;&#34;&#34;
import os
import sys

sys.path.append(os.path.dirname(os.path.realpath(__file__)))

from seqapp.config import *

from seqapp import app
from seqapp.utils import *


# logger = logging.getLogger(__name__)


def create_blank_df(header, index_name=&#34;NA&#34;):
    &#34;&#34;&#34;
    Function: create_blank_df
    Summary: InsertHere
    Examples: InsertHere
    Returns: InsertHere
    
    Args:
        header (TYPE): [...]
        index_name (str, optional): [...]
    
    Returns:
        TYPE: [...]
    &#34;&#34;&#34;
    blank_entry = pd.DataFrame(
        [*itl.chain.from_iterable([[np.nan] for _ in range(len(header))])]
    ).T
    blank_entry.index = [f&#34;{index_name}&#34;]
    blank_entry.columns = header
    return blank_entry



def get_N_quals(df):
    &#34;&#34;&#34;
    Parameters
    ----------
    df : pd.DataFrame
        Input df containing Sanger reads as rows w/ bases set to
        column &#39;seq&#39; and corresponding quality score
    
    Returns
    -------
    pd.DataFrame
        Containing quality scores only for &#39;N&#39; bases
    
    &#34;&#34;&#34;
    bqs = []
    for n in range(df.shape[0]):
        bqs.append(
            [
                (b, q)
                for (b, q) in [*zip(df.iloc[n].seq, df.iloc[n].Q_arrays)]
                if b == &#34;N&#34;
            ]
        )
    N_quals = [q for (b, q) in [*itl.chain.from_iterable(bqs)]]
    df_NQs = pd.Series(N_quals)
    return df_NQs, df_NQs.describe()




def parse_contents(contents, filename, date, f_wout, session_log_file):
    &#34;&#34;&#34;Parses user-uploaded input sequence files; namely, ABI Sanger
    Sequencing chromatogram &#39;trace&#39; files. However, a variety of
    other bioinformatics sequence file types are also accepted.

    Args:
        contents (bytes): uploaded input file data via Dash uploads component
        filename (str): file name of the uploaded input
        date (int?): date modified of uploaded input
        f_wout (TYPE): file path of current session to write decoded sequence data
        session_log_file (str, optional): Deprecated [→No longer explicitly passing around log file paths.]

    Returns:
        list: Components array showing all uploaded files and displaying the 
              decoded FASTQ sequences and corresponding linear quality scores
    &#34;&#34;&#34;
    # P A R S E   F I L E   U P L O A D  I N P U T S
    content_type, content_string = contents.split(&#34;,&#34;)
    decoded = base64.b64decode(content_string)
    try:
        ## READ IN : AB1 - SANGER
        # Chromatogram Sanger reads files
        if filename.endswith(&#34;ab1&#34;):
            abi_decoded = io.BytesIO(decoded)
            df = abi2fastq(
                input_abi=filename,
                abi_contents=abi_decoded,
                f_wout=f_wout,
                abi_encoded=content_string,
            )
            if df.shape[0] &lt; 1:
                return html.Div(
                    [
                        &#34;There was an error processing this file.\n(\tTraceback:\n&#34;
                        + f&#34;{e}\n\t).&#34;
                    ]
                )
        ## READ IN : FASTA - (ASSUME TCRα/β ligations)
        # TCR-alpha/beta allele-specific chain pairs sequences
        # i.e., Assume this is the refernce file already given by user.
        elif filename.endswith(tuple([&#34;.fa&#34;, &#34;.fasta&#34;, &#34;.FASTA&#34;])):
            df, ref = parse_input_ref_fasta(
                input_fa=filename, fa_contents=io.StringIO(decoded.decode(&#34;utf-8&#34;))
            )
        ## READ IN : FASTQ - (ASSUME TCRα/β ligations)
        # TCR-alpha/beta allele-specific chain pairs sequences
        elif filename.endswith(tuple([&#34;.fq&#34;, &#34;.fastq&#34;, &#34;.FASTQ&#34;])):
            fastq = SeqIO.parse(io.StringIO(decoded), &#34;fastq&#34;)
        ## READ IN : ARBITRARY DATA TABLES
        elif &#34;csv&#34; in filename:  # or &#34;tsv&#34; in filename:
            # Assume that the user uploaded a CSV file
            df = pd.read_csv(io.StringIO(decoded.decode(&#34;utf-8&#34;)))
        elif &#34;xls&#34; in filename:
            # Assume that the user uploaded an Excel file
            df = pd.read_excel(io.BytesIO(decoded))
    except Exception as e:
        print(e)
        traceback.print_exc(file=sys.stdout)
        return html.Div(
            [
                f&#34;⚠🤮:📄⤞🛇 There was an error processing this file: {filename}.\n(\tTraceback:\n&#34;
                + f&#34;{e}\n\t).&#34;
            ]
        )
    return html.Div(
        [
            html.H5(filename),
            html.H6(now()),
            dash_table.DataTable(
                data=df.to_dict(&#34;rows&#34;),
                columns=[{&#34;id&#34;: c, &#34;name&#34;: c} for c in df.columns],
                style_table={
                    &#34;maxHeight&#34;: &#34;600px&#34;,
                    &#34;overflowY&#34;: &#34;auto&#34;,
                    &#34;overflowX&#34;: &#34;auto&#34;,
                },
                style_cell={
                    &#34;fontFamily&#34;: &#34;Muli&#34;,
                    &#34;fontSize&#34;: &#34;0.7rem&#34;,
                    &#34;whiteSpace&#34;: &#34;normal&#34;,
                    &#34;padding&#34;: &#34;3px&#34;,
                    &#34;textOverflow&#34;: &#34;ellipsis&#34;,
                    &#34;textAlign&#34;: &#34;left&#34;,
                },
                style_header={
                    &#34;fontWeight&#34;: &#34;bold&#34;,
                    &#34;fontSize&#34;: &#34;0.8rem&#34;,
                    &#34;cursor&#34;: &#34;pointer&#34;,
                    &#34;color&#34;: &#34;rgba(0,0,180,0.75)&#34;,
                },
            ),
            html.Div(&#34;Raw Content&#34;),
            html.Pre(
                contents[0:200] + &#34;...&#34;,
                style={&#34;whiteSpace&#34;: &#34;pre-wrap&#34;, &#34;wordBreak&#34;: &#34;break-all&#34;},
            ),
        ]
    )


def q2p(phred_Sanger_Quality_score):
    &#34;&#34;&#34;Quality [score] to probability (q2p)
    converter.
    
    Args:
        phred_Sanger_Quality_score (str): Input Q-Score as single-character string
    
    Returns:
        int: Output Q-Score as multi-character decimal probability.
    &#34;&#34;&#34;
    Q = ord(phred_Sanger_Quality_score) - 33
    return round(10 ** (-Q / 10), 8)


def read_fasta(fa_contents, fa_out=None):
    &#34;&#34;&#34;Parse input FASTA data.
    
    Args:
        fa_contents (TYPE): [...]
        fa_out (str, optional): [.fasta] output file path
    
    Returns:
        pd.DataFrame: Columnar tabulated FASTA data
    &#34;&#34;&#34;
    fa_records = [*SeqIO.parse(fa_contents, &#34;fasta&#34;)]
    app.logger.info(fa_records)
    reads = pd.concat(
        [
            pd.DataFrame(
                {x: str(getattr(seqr, x)) for x in [&#34;id&#34;, &#34;name&#34;, &#34;seq&#34;, &#34;[...]&#34;]},
                index=[n],
            )
            for n, seqr in enumerate(fa_records)
        ]
    )
    reads.set_index(&#34;id&#34;, inplace=True)
    if fa_out:
        app.logger.info(f&#34;Writing FASTA output for file: {fa_out}&#34;)
        SeqIO.write(fa_records, fa_out, &#34;fasta&#34;)
        reads.to_csv(fa_out + &#34;.DataFrame.tsv&#34;, sep=&#34;\t&#34;)
    return reads


def run_pipeline(
    RUN_ID, FINAL_OUTPUT_DIR, prefix_key=&#34;&#34;, exp=&#34;&#34;, well=&#34;&#34;, workflow=&#34;&#34;, session_log_file=&#34;&#34;
):
    &#34;&#34;&#34;Main parallelization of mapping &amp; variant caller commands.

    Args:
        RUN_ID (str): Current RUN ID (e.g., SEQAPP_RUNID_20191103224547407862)
        FINAL_OUTPUT_DIR (str): local path to current session output directory
        exp (str, optional): Experiment ID
        well (str, optional): Plate Well ID
        workflow (str, optional): upstream process team 
        session_log_file (str, optional): path to current session log file
    &#34;&#34;&#34;
    detected = [
        *filter(lambda dir: dir.startswith(prefix_key), os.listdir(FINAL_OUTPUT_DIR))
    ]
    app.logger.info(f&#34;Samples detected: \n {detected}&#34;)
    with mp.Pool(processes=((mp.cpu_count() * 2) + 1)) as p:
        pipeline_stream = p.map(
            partial(
                run_sequence_alignment_with_sangerseqqc,
                RUN_ID=RUN_ID,
                FINAL_OUTPUT_DIR=FINAL_OUTPUT_DIR,
                exp=exp,
                well=well,
                workflow=workflow,
                session_log_file=session_log_file,
            ),
            (*(detected),),
        )
    return pipeline_stream


def wrap_seq_nucleic(seq, wrap=125):
    &#34;&#34;&#34;Wraps input genetic sequence strings and returns
    tuple of &#39;wrap&#39;-limited width with tuple zipped numeric
    indeces which can optionally be printed alongside each
    line of sequence code.

    Args:
        seq (str): DNA/RNA/AA sequence to display
        wrap (int, optional): set displayed sequence line length

    Returns:
        zipped tuple: of paired (wrapped seq text, seq index) values per line
    &#34;&#34;&#34;
    seq_lines = [seq[x_i : x_i + wrap] for x_i in range(0, len(seq), wrap)]
    seq_indeces = [
        (
            &#34;&#34;.join(
                [
                    f&#34;000{str(x_i)}&#34;[-4:] + &#34;:....&#34; * 4 + &#34;|&#34;
                    for x_i in range(
                        len(ljoin(seq_lines[: n - 1])), len(ljoin(seq_lines[:n])), 25
                    )
                ]
            )
        )[: len(seq_lines[n - 1])]
        for n in range(1, len(seq_lines) + 1)
    ]
    return zip(seqlines, seq_indeces)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dash-webapp-template.seqapp.bioinfo.pipeline.create_blank_df"><code class="name flex">
<span>def <span class="ident">create_blank_df</span></span>(<span>header, index_name='NA')</span>
</code></dt>
<dd>
<div class="desc"><p>Function: create_blank_df
Summary: InsertHere
Examples: InsertHere
Returns: InsertHere</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>header</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>[&hellip;]</dd>
<dt><strong><code>index_name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[&hellip;]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>TYPE</code></dt>
<dd>[&hellip;]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_blank_df(header, index_name=&#34;NA&#34;):
    &#34;&#34;&#34;
    Function: create_blank_df
    Summary: InsertHere
    Examples: InsertHere
    Returns: InsertHere
    
    Args:
        header (TYPE): [...]
        index_name (str, optional): [...]
    
    Returns:
        TYPE: [...]
    &#34;&#34;&#34;
    blank_entry = pd.DataFrame(
        [*itl.chain.from_iterable([[np.nan] for _ in range(len(header))])]
    ).T
    blank_entry.index = [f&#34;{index_name}&#34;]
    blank_entry.columns = header
    return blank_entry</code></pre>
</details>
</dd>
<dt id="dash-webapp-template.seqapp.bioinfo.pipeline.get_N_quals"><code class="name flex">
<span>def <span class="ident">get_N_quals</span></span>(<span>df)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Input df containing Sanger reads as rows w/ bases set to
column 'seq' and corresponding quality score</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>Containing quality scores only for 'N' bases</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_N_quals(df):
    &#34;&#34;&#34;
    Parameters
    ----------
    df : pd.DataFrame
        Input df containing Sanger reads as rows w/ bases set to
        column &#39;seq&#39; and corresponding quality score
    
    Returns
    -------
    pd.DataFrame
        Containing quality scores only for &#39;N&#39; bases
    
    &#34;&#34;&#34;
    bqs = []
    for n in range(df.shape[0]):
        bqs.append(
            [
                (b, q)
                for (b, q) in [*zip(df.iloc[n].seq, df.iloc[n].Q_arrays)]
                if b == &#34;N&#34;
            ]
        )
    N_quals = [q for (b, q) in [*itl.chain.from_iterable(bqs)]]
    df_NQs = pd.Series(N_quals)
    return df_NQs, df_NQs.describe()</code></pre>
</details>
</dd>
<dt id="dash-webapp-template.seqapp.bioinfo.pipeline.parse_contents"><code class="name flex">
<span>def <span class="ident">parse_contents</span></span>(<span>contents, filename, date, f_wout, session_log_file)</span>
</code></dt>
<dd>
<div class="desc"><p>Parses user-uploaded input sequence files; namely, ABI Sanger
Sequencing chromatogram 'trace' files. However, a variety of
other bioinformatics sequence file types are also accepted.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>contents</code></strong> :&ensp;<code>bytes</code></dt>
<dd>uploaded input file data via Dash uploads component</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>file name of the uploaded input</dd>
<dt>date (int?): date modified of uploaded input</dt>
<dt><strong><code>f_wout</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>file path of current session to write decoded sequence data</dd>
<dt><strong><code>session_log_file</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Deprecated [→No longer explicitly passing around log file paths.]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>Components array showing all uploaded files and displaying the
decoded FASTQ sequences and corresponding linear quality scores</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_contents(contents, filename, date, f_wout, session_log_file):
    &#34;&#34;&#34;Parses user-uploaded input sequence files; namely, ABI Sanger
    Sequencing chromatogram &#39;trace&#39; files. However, a variety of
    other bioinformatics sequence file types are also accepted.

    Args:
        contents (bytes): uploaded input file data via Dash uploads component
        filename (str): file name of the uploaded input
        date (int?): date modified of uploaded input
        f_wout (TYPE): file path of current session to write decoded sequence data
        session_log_file (str, optional): Deprecated [→No longer explicitly passing around log file paths.]

    Returns:
        list: Components array showing all uploaded files and displaying the 
              decoded FASTQ sequences and corresponding linear quality scores
    &#34;&#34;&#34;
    # P A R S E   F I L E   U P L O A D  I N P U T S
    content_type, content_string = contents.split(&#34;,&#34;)
    decoded = base64.b64decode(content_string)
    try:
        ## READ IN : AB1 - SANGER
        # Chromatogram Sanger reads files
        if filename.endswith(&#34;ab1&#34;):
            abi_decoded = io.BytesIO(decoded)
            df = abi2fastq(
                input_abi=filename,
                abi_contents=abi_decoded,
                f_wout=f_wout,
                abi_encoded=content_string,
            )
            if df.shape[0] &lt; 1:
                return html.Div(
                    [
                        &#34;There was an error processing this file.\n(\tTraceback:\n&#34;
                        + f&#34;{e}\n\t).&#34;
                    ]
                )
        ## READ IN : FASTA - (ASSUME TCRα/β ligations)
        # TCR-alpha/beta allele-specific chain pairs sequences
        # i.e., Assume this is the refernce file already given by user.
        elif filename.endswith(tuple([&#34;.fa&#34;, &#34;.fasta&#34;, &#34;.FASTA&#34;])):
            df, ref = parse_input_ref_fasta(
                input_fa=filename, fa_contents=io.StringIO(decoded.decode(&#34;utf-8&#34;))
            )
        ## READ IN : FASTQ - (ASSUME TCRα/β ligations)
        # TCR-alpha/beta allele-specific chain pairs sequences
        elif filename.endswith(tuple([&#34;.fq&#34;, &#34;.fastq&#34;, &#34;.FASTQ&#34;])):
            fastq = SeqIO.parse(io.StringIO(decoded), &#34;fastq&#34;)
        ## READ IN : ARBITRARY DATA TABLES
        elif &#34;csv&#34; in filename:  # or &#34;tsv&#34; in filename:
            # Assume that the user uploaded a CSV file
            df = pd.read_csv(io.StringIO(decoded.decode(&#34;utf-8&#34;)))
        elif &#34;xls&#34; in filename:
            # Assume that the user uploaded an Excel file
            df = pd.read_excel(io.BytesIO(decoded))
    except Exception as e:
        print(e)
        traceback.print_exc(file=sys.stdout)
        return html.Div(
            [
                f&#34;⚠🤮:📄⤞🛇 There was an error processing this file: {filename}.\n(\tTraceback:\n&#34;
                + f&#34;{e}\n\t).&#34;
            ]
        )
    return html.Div(
        [
            html.H5(filename),
            html.H6(now()),
            dash_table.DataTable(
                data=df.to_dict(&#34;rows&#34;),
                columns=[{&#34;id&#34;: c, &#34;name&#34;: c} for c in df.columns],
                style_table={
                    &#34;maxHeight&#34;: &#34;600px&#34;,
                    &#34;overflowY&#34;: &#34;auto&#34;,
                    &#34;overflowX&#34;: &#34;auto&#34;,
                },
                style_cell={
                    &#34;fontFamily&#34;: &#34;Muli&#34;,
                    &#34;fontSize&#34;: &#34;0.7rem&#34;,
                    &#34;whiteSpace&#34;: &#34;normal&#34;,
                    &#34;padding&#34;: &#34;3px&#34;,
                    &#34;textOverflow&#34;: &#34;ellipsis&#34;,
                    &#34;textAlign&#34;: &#34;left&#34;,
                },
                style_header={
                    &#34;fontWeight&#34;: &#34;bold&#34;,
                    &#34;fontSize&#34;: &#34;0.8rem&#34;,
                    &#34;cursor&#34;: &#34;pointer&#34;,
                    &#34;color&#34;: &#34;rgba(0,0,180,0.75)&#34;,
                },
            ),
            html.Div(&#34;Raw Content&#34;),
            html.Pre(
                contents[0:200] + &#34;...&#34;,
                style={&#34;whiteSpace&#34;: &#34;pre-wrap&#34;, &#34;wordBreak&#34;: &#34;break-all&#34;},
            ),
        ]
    )</code></pre>
</details>
</dd>
<dt id="dash-webapp-template.seqapp.bioinfo.pipeline.q2p"><code class="name flex">
<span>def <span class="ident">q2p</span></span>(<span>phred_Sanger_Quality_score)</span>
</code></dt>
<dd>
<div class="desc"><p>Quality [score] to probability (q2p)
converter.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>phred_Sanger_Quality_score</code></strong> :&ensp;<code>str</code></dt>
<dd>Input Q-Score as single-character string</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>Output Q-Score as multi-character decimal probability.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def q2p(phred_Sanger_Quality_score):
    &#34;&#34;&#34;Quality [score] to probability (q2p)
    converter.
    
    Args:
        phred_Sanger_Quality_score (str): Input Q-Score as single-character string
    
    Returns:
        int: Output Q-Score as multi-character decimal probability.
    &#34;&#34;&#34;
    Q = ord(phred_Sanger_Quality_score) - 33
    return round(10 ** (-Q / 10), 8)</code></pre>
</details>
</dd>
<dt id="dash-webapp-template.seqapp.bioinfo.pipeline.read_fasta"><code class="name flex">
<span>def <span class="ident">read_fasta</span></span>(<span>fa_contents, fa_out=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Parse input FASTA data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fa_contents</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>[&hellip;]</dd>
<dt><strong><code>fa_out</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[.fasta] output file path</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>Columnar tabulated FASTA data</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_fasta(fa_contents, fa_out=None):
    &#34;&#34;&#34;Parse input FASTA data.
    
    Args:
        fa_contents (TYPE): [...]
        fa_out (str, optional): [.fasta] output file path
    
    Returns:
        pd.DataFrame: Columnar tabulated FASTA data
    &#34;&#34;&#34;
    fa_records = [*SeqIO.parse(fa_contents, &#34;fasta&#34;)]
    app.logger.info(fa_records)
    reads = pd.concat(
        [
            pd.DataFrame(
                {x: str(getattr(seqr, x)) for x in [&#34;id&#34;, &#34;name&#34;, &#34;seq&#34;, &#34;[...]&#34;]},
                index=[n],
            )
            for n, seqr in enumerate(fa_records)
        ]
    )
    reads.set_index(&#34;id&#34;, inplace=True)
    if fa_out:
        app.logger.info(f&#34;Writing FASTA output for file: {fa_out}&#34;)
        SeqIO.write(fa_records, fa_out, &#34;fasta&#34;)
        reads.to_csv(fa_out + &#34;.DataFrame.tsv&#34;, sep=&#34;\t&#34;)
    return reads</code></pre>
</details>
</dd>
<dt id="dash-webapp-template.seqapp.bioinfo.pipeline.run_pipeline"><code class="name flex">
<span>def <span class="ident">run_pipeline</span></span>(<span>RUN_ID, FINAL_OUTPUT_DIR, prefix_key='', exp='', well='', workflow='', session_log_file='')</span>
</code></dt>
<dd>
<div class="desc"><p>Main parallelization of mapping &amp; variant caller commands.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>RUN_ID</code></strong> :&ensp;<code>str</code></dt>
<dd>Current RUN ID (e.g., SEQAPP_RUNID_20191103224547407862)</dd>
<dt><strong><code>FINAL_OUTPUT_DIR</code></strong> :&ensp;<code>str</code></dt>
<dd>local path to current session output directory</dd>
<dt><strong><code>exp</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Experiment ID</dd>
<dt><strong><code>well</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Plate Well ID</dd>
<dt><strong><code>workflow</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>upstream process team </dd>
<dt><strong><code>session_log_file</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>path to current session log file</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_pipeline(
    RUN_ID, FINAL_OUTPUT_DIR, prefix_key=&#34;&#34;, exp=&#34;&#34;, well=&#34;&#34;, workflow=&#34;&#34;, session_log_file=&#34;&#34;
):
    &#34;&#34;&#34;Main parallelization of mapping &amp; variant caller commands.

    Args:
        RUN_ID (str): Current RUN ID (e.g., SEQAPP_RUNID_20191103224547407862)
        FINAL_OUTPUT_DIR (str): local path to current session output directory
        exp (str, optional): Experiment ID
        well (str, optional): Plate Well ID
        workflow (str, optional): upstream process team 
        session_log_file (str, optional): path to current session log file
    &#34;&#34;&#34;
    detected = [
        *filter(lambda dir: dir.startswith(prefix_key), os.listdir(FINAL_OUTPUT_DIR))
    ]
    app.logger.info(f&#34;Samples detected: \n {detected}&#34;)
    with mp.Pool(processes=((mp.cpu_count() * 2) + 1)) as p:
        pipeline_stream = p.map(
            partial(
                run_sequence_alignment_with_sangerseqqc,
                RUN_ID=RUN_ID,
                FINAL_OUTPUT_DIR=FINAL_OUTPUT_DIR,
                exp=exp,
                well=well,
                workflow=workflow,
                session_log_file=session_log_file,
            ),
            (*(detected),),
        )
    return pipeline_stream</code></pre>
</details>
</dd>
<dt id="dash-webapp-template.seqapp.bioinfo.pipeline.wrap_seq_nucleic"><code class="name flex">
<span>def <span class="ident">wrap_seq_nucleic</span></span>(<span>seq, wrap=125)</span>
</code></dt>
<dd>
<div class="desc"><p>Wraps input genetic sequence strings and returns
tuple of 'wrap'-limited width with tuple zipped numeric
indeces which can optionally be printed alongside each
line of sequence code.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>seq</code></strong> :&ensp;<code>str</code></dt>
<dd>DNA/RNA/AA sequence to display</dd>
<dt><strong><code>wrap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>set displayed sequence line length</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>zipped tuple</code></dt>
<dd>of paired (wrapped seq text, seq index) values per line</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wrap_seq_nucleic(seq, wrap=125):
    &#34;&#34;&#34;Wraps input genetic sequence strings and returns
    tuple of &#39;wrap&#39;-limited width with tuple zipped numeric
    indeces which can optionally be printed alongside each
    line of sequence code.

    Args:
        seq (str): DNA/RNA/AA sequence to display
        wrap (int, optional): set displayed sequence line length

    Returns:
        zipped tuple: of paired (wrapped seq text, seq index) values per line
    &#34;&#34;&#34;
    seq_lines = [seq[x_i : x_i + wrap] for x_i in range(0, len(seq), wrap)]
    seq_indeces = [
        (
            &#34;&#34;.join(
                [
                    f&#34;000{str(x_i)}&#34;[-4:] + &#34;:....&#34; * 4 + &#34;|&#34;
                    for x_i in range(
                        len(ljoin(seq_lines[: n - 1])), len(ljoin(seq_lines[:n])), 25
                    )
                ]
            )
        )[: len(seq_lines[n - 1])]
        for n in range(1, len(seq_lines) + 1)
    ]
    return zip(seqlines, seq_indeces)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#overview">Overview</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dash-webapp-template.seqapp.bioinfo" href="index.html">dash-webapp-template.seqapp.bioinfo</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="dash-webapp-template.seqapp.bioinfo.pipeline.create_blank_df" href="#dash-webapp-template.seqapp.bioinfo.pipeline.create_blank_df">create_blank_df</a></code></li>
<li><code><a title="dash-webapp-template.seqapp.bioinfo.pipeline.get_N_quals" href="#dash-webapp-template.seqapp.bioinfo.pipeline.get_N_quals">get_N_quals</a></code></li>
<li><code><a title="dash-webapp-template.seqapp.bioinfo.pipeline.parse_contents" href="#dash-webapp-template.seqapp.bioinfo.pipeline.parse_contents">parse_contents</a></code></li>
<li><code><a title="dash-webapp-template.seqapp.bioinfo.pipeline.q2p" href="#dash-webapp-template.seqapp.bioinfo.pipeline.q2p">q2p</a></code></li>
<li><code><a title="dash-webapp-template.seqapp.bioinfo.pipeline.read_fasta" href="#dash-webapp-template.seqapp.bioinfo.pipeline.read_fasta">read_fasta</a></code></li>
<li><code><a title="dash-webapp-template.seqapp.bioinfo.pipeline.run_pipeline" href="#dash-webapp-template.seqapp.bioinfo.pipeline.run_pipeline">run_pipeline</a></code></li>
<li><code><a title="dash-webapp-template.seqapp.bioinfo.pipeline.wrap_seq_nucleic" href="#dash-webapp-template.seqapp.bioinfo.pipeline.wrap_seq_nucleic">wrap_seq_nucleic</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>